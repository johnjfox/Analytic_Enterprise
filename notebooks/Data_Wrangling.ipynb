{
  "cells": [
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "# Data Wrangling Fundamentals in Python"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "<div class=\"alert alert-info\">\nThis notebook is intended only to provide an overview of the capabilities of the pandas package. More complete documentation can be found at\n<ul>\n<li><a href=\"http://pandas.pydata.org/pandas-docs/stable/merging.html\">Pandas Data Merging</a></li>\n</ul>\n</div>"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "<div class=\"alert alert-danger\">\nYou'll need to have an internet connection for portions of this notebook.\n</div>"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "## Introduction"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "Data wrangling is a loosely defined process for manually converting or mapping data from one \"raw\" form into another format. The purpose of this wrangling is to recast the data into a format which either simoplifies our processing chain or enables us to use tools which require a certain layout of the data. Typically data wrangling is one of the first steps in  the processing once we extract the data from the data source."
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "The process of wrangling can involve a broad variety of operations, such as sorting, filtering, or other operations. Many of these are covered elsewhere in our materials, so for the purposes of this chapter, we'll emphasize wrangling operations which involve reshaping data or combining multiple sets of data."
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "### Initialization of Notebook"
    }, 
    {
      "cell_type": "code", 
      "execution_count": 1, 
      "metadata": {}, 
      "outputs": [], 
      "source": "# Our standard set of imports for pandas, numpy and matplotlib\nimport pandas as pd\nimport numpy as np\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# in addition, it will be useful in general if we keep our plots \"inline\" within the notebook\n%matplotlib inline\n\n# finally, let's use a style that's a bit pretty than the default\nmpl.style.use('ggplot')"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "## Reshaping Data"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "The data that we have in the iris.data.csv file is what's called \"wide-format\" data, meaning that each line in the file contains a column for each variable. Wide-format data is almost certainly what you're most familiar with, since it's the format most commonly used to organize tabular data in Excel and, frankly, the notion of arranging all of the variable into a single row to represent a single observation feels pretty natural."
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "In contrast, \"long-format\" data has a column for possible variable types and a column for the values of those variables. If you're like most people, then that description is probably pretty hard to get a handle on. To be honest, you're not alone. Frankly, it's much easier to actually see what long-format data looks like than it is to describe it, so why don't we work through a simple example."
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "Before we get started, let's make sure that we have a copy of our favorite DataFrame, the iris data set and remind ourselves of the layout of the data."
    }, 
    {
      "cell_type": "code", 
      "execution_count": 2, 
      "metadata": {}, 
      "outputs": [
        {
          "data": {
            "text/plain": "   ID  Sepal_Length  Sepal_Width  Petal_Length  Petal_Width        Class\n0   1           5.1          3.5           1.4          0.2  Iris-setosa\n1   2           4.9          3.0           1.4          0.2  Iris-setosa\n2   3           4.7          3.2           1.3          0.2  Iris-setosa\n3   4           4.6          3.1           1.5          0.2  Iris-setosa\n4   5           5.0          3.6           1.4          0.2  Iris-setosa\n5   6           5.4          3.9           1.7          0.4  Iris-setosa\n6   7           4.6          3.4           1.4          0.3  Iris-setosa\n7   8           5.0          3.4           1.5          0.2  Iris-setosa\n8   9           4.4          2.9           1.4          0.2  Iris-setosa\n9  10           4.9          3.1           1.5          0.1  Iris-setosa"
          }, 
          "execution_count": 2, 
          "metadata": {}, 
          "output_type": "execute_result"
        }
      ], 
      "source": "# Let's set up a URL to the file, which in this case is hosted on github\nbase_url = 'https://raw.githubusercontent.com/johnjfox/Analytic_Enterprise/master/data/'\ndata_url = 'iris/iris.data.csv'\nurl = base_url + data_url\n\n# Now let's read the file\ndf = pd.read_csv(url)\n\n# Finally, let's print the first few lines\nprint df.head(10)"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "As you can see (and probably remember), each row has **all** of the data associated with our measurements for any one of the irises. Now, let's look at what happens if we convert this to long-format. In python, we do this using the *melt()* method."
    }, 
    {
      "cell_type": "code", 
      "execution_count": 3, 
      "metadata": {}, 
      "outputs": [
        {
          "data": {
            "text/plain": "         Class   measurement  value\n0  Iris-setosa  Sepal_Length    5.1\n1  Iris-setosa  Sepal_Length    4.9\n2  Iris-setosa  Sepal_Length    4.7\n3  Iris-setosa  Sepal_Length    4.6\n4  Iris-setosa  Sepal_Length    5.0\n5  Iris-setosa  Sepal_Length    5.4\n6  Iris-setosa  Sepal_Length    4.6\n7  Iris-setosa  Sepal_Length    5.0\n8  Iris-setosa  Sepal_Length    4.4\n9  Iris-setosa  Sepal_Length    4.9"
          }, 
          "execution_count": 3, 
          "metadata": {}, 
          "output_type": "execute_result"
        }
      ], 
      "source": "# first, let's drop the ID column\ndf_noID = df.drop(['ID'],axis=1)\n\ndf_melt = pd.melt(df_noID,'Class', var_name='measurement')\nprint df_melt.head(10)"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "So, what just happened there? First, we dropped the ID variable. You'll probably be able to tell why in a moment, but just trust me on this for now. The more interesting operation was the *melt()*. The process of \"melting\" the original DataFrame essentially pulled apart the data and created a new representation. After the melt, we have a format where one or more columns are identifier variables (in this case the contents of the \"Class\" variable). The only other columns in the new DataFrame are columns containing \u201cvariable names\u201d and \u201cvalues\u201d. If you're familiar with MS Excel pivot tables, this might feel like we did the inverse of a pivot table operation.  In this representation, each of the values in the table now appears on a separate row, whereas before all of the related variable were collected into a"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "So, why did we do this? First off, we'll often receive data in a format that doesn't lend itself to analysis. This can happen in a lot of ways, for instance:"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "* Column headers are values, not variable names.\n* Multiple variables are stored in one column.\n* Variables are stored in both rows and columns.\n* Multiple types of observational units are stored in the same table.   \n* A single observational unit is stored in multiple tables."
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "Melting the data is often the first step in reshaping the data into a format that is more amenable to analysis. Either we'll melt the data as an end unto itself, or we might use some of the other pandas operations (e.g. pivot or groupby) to reshape into a different form."
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "#### Wide-format versus long-format representations"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "So what kinds of analyses are particularly appropriate for wide format data. Well, as it turns out, most of the analyses that we've seen to this point work quite well with wide-format data. For instance, if we want to perform any form of visual or descriptive analysis of a single variable, wide-format data is extremely convenient since we have convenience methods that allow us to extract the data. For instance:"
    }, 
    {
      "cell_type": "code", 
      "execution_count": 4, 
      "metadata": {}, 
      "outputs": [
        {
          "data": {
            "text/plain": "\n\nMEAN =  count    150.000000\nmean       1.198667\nstd        0.763161\nmin        0.100000\n25%        0.300000\n50%        1.300000\n75%        1.800000\nmax        2.500000\nName: Petal_Width, dtype: float64\n\n\n==============================="
          }, 
          "execution_count": 4, 
          "metadata": {}, 
          "output_type": "execute_result"
        }
      ], 
      "source": "print \"\\n\\nMEAN = \", df.Petal_Width.describe()\n\nprint \"\\n\\n===============================\\n\\n\"\n\nfig, axes = plt.subplots(nrows=1, ncols=1, sharex=True, figsize=(6,4.5))\n\nsns.distplot(df.Petal_Width, rug=True, bins=10);"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "Similarly, having columns representing distinct variables, all of which are taken from the same observation, makes it very easy to compare or manipulate those variables. For instance, we can easily create a scatter plot or measure the correlation of the variables:"
    }, 
    {
      "cell_type": "code", 
      "execution_count": 5, 
      "metadata": {}, 
      "outputs": [], 
      "source": "df.plot.scatter('Petal_Width', 'Petal_Length', figsize=(6,4.5));"
    }, 
    {
      "cell_type": "code", 
      "execution_count": 6, 
      "metadata": {}, 
      "outputs": [
        {
          "data": {
            "text/plain": "                    ID  Sepal_Length  Sepal_Width  Petal_Length  Petal_Width\nID            1.000000      0.716676    -0.397729      0.882747     0.899759\nSepal_Length  0.716676      1.000000    -0.109369      0.871754     0.817954\nSepal_Width  -0.397729     -0.109369     1.000000     -0.420516    -0.356544\nPetal_Length  0.882747      0.871754    -0.420516      1.000000     0.962757\nPetal_Width   0.899759      0.817954    -0.356544      0.962757     1.000000"
          }, 
          "execution_count": 6, 
          "metadata": {}, 
          "output_type": "execute_result"
        }
      ], 
      "source": "# the pairwise correlation of each variable in the table\ndf.corr()"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "Now, consider this application of using the melted data. Notice one thing that happened as a result of the *melt()*: The variable names are now being treated as categorical variables in the new DataFrame. This can be exceptionally useful for exploratory analysis where we'd like to get a holistic view of all of the data in a single plot. For instance, consider a stripplot of all of the iris data as shown below;"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "Long-format data isn\u2019t necessarily only two columns. For example, we might have ozone measurements for each day of the year. In that case, we could have another column for day. In other words, there are different levels of \u201clongness\u201d. The ultimate shape you want to get your data into will depend on what you are doing with it."
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "It turns out that you need wide-format data for some types of data analysis and long-format data for others. In reality, you need long-format data much more commonly than wide-format data."
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "Here, the process of melting the iris data has ended up with a DataFrame where we can use the original variable names to partition the measurements. By using the categorical identifier variable (\"Class\") to determine the hue of each datapoint, we can easily see that the Petal_Length and Petal_Width are separable for one of the classes of irises."
    }, 
    {
      "cell_type": "code", 
      "execution_count": 7, 
      "metadata": {}, 
      "outputs": [], 
      "source": "plt.figure(figsize=(6,6))\nsns.stripplot(y='value', x='measurement', hue='Class', data=df_melt, jitter= True);"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "## Data Merging"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "We already saw how to"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "Let's recall the contents of our original wide-format DataFrame:"
    }, 
    {
      "cell_type": "code", 
      "execution_count": 8, 
      "metadata": {}, 
      "outputs": [
        {
          "data": {
            "text/plain": "   ID  Sepal_Length  Sepal_Width  Petal_Length  Petal_Width        Class\n0   1           5.1          3.5           1.4          0.2  Iris-setosa\n1   2           4.9          3.0           1.4          0.2  Iris-setosa\n2   3           4.7          3.2           1.3          0.2  Iris-setosa\n3   4           4.6          3.1           1.5          0.2  Iris-setosa\n4   5           5.0          3.6           1.4          0.2  Iris-setosa\n5   6           5.4          3.9           1.7          0.4  Iris-setosa\n6   7           4.6          3.4           1.4          0.3  Iris-setosa\n7   8           5.0          3.4           1.5          0.2  Iris-setosa\n8   9           4.4          2.9           1.4          0.2  Iris-setosa\n9  10           4.9          3.1           1.5          0.1  Iris-setosa"
          }, 
          "execution_count": 8, 
          "metadata": {}, 
          "output_type": "execute_result"
        }
      ], 
      "source": "df.head(10)"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "Now, what if we wanted to merge this data with some other data set, say a table that contained the prices for each class of iris. You could imagine that such a table might look like the following (although we wouldn't be generating the data randomly):"
    }, 
    {
      "cell_type": "code", 
      "execution_count": 9, 
      "metadata": {}, 
      "outputs": [
        {
          "data": {
            "text/plain": "             Class     price\n0      Iris-setosa  2.377915\n1  Iris-versicolor  6.300895\n2   Iris-virginica  3.006378\n3      iris-fakosa  4.937169"
          }, 
          "execution_count": 9, 
          "metadata": {}, 
          "output_type": "execute_result"
        }
      ], 
      "source": "# some random price data\ndata = {'Class' : ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica', 'iris-fakosa'],\n        'price' : np.random.uniform(0,10,4)}\nprice_df = pd.DataFrame(data, columns=['Class', 'price'])\nprice_df"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "### Merging Via a Join"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "Users of relational databases will be familiar with the terminology used to describe join operations between two table like structures, in our case DataFrame objects. There are several cases to consider which are very important to understand:"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "* one-to-one joins: for example when joining two DataFrame objects on their indexes (which must contain unique values)\n* many-to-one joins: for example when joining an index (unique) to one or more columns in a DataFrame\n* many-to-many joins: joining columns on columns."
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "pandas supports the combination of DataFrames through the \"join\" operations that most people are familiar with from relational databases. One common type of join operation is the \"inner join\". The most general purpose method for performing this is the *merge()* operator, which supports the following types of operations"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "| merge method | SQL Join Name | Description | \n| :---: | :--- | :--- |\n| left\t| LEFT OUTER JOIN | \tUse keys from left frame only |\n| right\t| RIGHT OUTER JOIN | Use keys from right frame only | \n| outer\t| FULL OUTER JOIN | Use union of keys from both frames | \n| inner\t| INNER JOIN | Use intersection of keys from both frames |"
    }, 
    {
      "cell_type": "code", 
      "execution_count": 10, 
      "metadata": {}, 
      "outputs": [
        {
          "data": {
            "text/plain": "      ID  Sepal_Length  Sepal_Width  Petal_Length  Petal_Width  \\\n36    37           5.5          3.5           1.3          0.2\n118  119           7.7          2.6           6.9          2.3\n140  141           6.7          3.1           5.6          2.4\n42    43           4.4          3.2           1.3          0.2\n25    26           5.0          3.0           1.6          0.2\n77    78           6.7          3.0           5.0          1.7\n13    14           4.3          3.0           1.1          0.1\n29    30           4.7          3.2           1.6          0.2\n23    24           5.1          3.3           1.7          0.5\n129  130           7.2          3.0           5.8          1.6\n\n               Class\n36       Iris-setosa\n118   Iris-virginica\n140   Iris-virginica\n42       Iris-setosa\n25       Iris-setosa\n77   Iris-versicolor\n13       Iris-setosa\n29       Iris-setosa\n23       Iris-setosa\n129   Iris-virginica"
          }, 
          "execution_count": 10, 
          "metadata": {}, 
          "output_type": "execute_result"
        }
      ], 
      "source": "# let's start by taking a random sample of the iris data so we can see a bit of diversity in the 'Class' variable\nrandom_df = df.sample(n=10)\nrandom_df"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "Now, using this sample of the data, let's join the price data to each row using the Class variable."
    }, 
    {
      "cell_type": "code", 
      "execution_count": 11, 
      "metadata": {}, 
      "outputs": [
        {
          "data": {
            "text/plain": "    ID  Sepal_Length  Sepal_Width  Petal_Length  Petal_Width            Class  \\\n0   37           5.5          3.5           1.3          0.2      Iris-setosa\n1   43           4.4          3.2           1.3          0.2      Iris-setosa\n2   26           5.0          3.0           1.6          0.2      Iris-setosa\n3   14           4.3          3.0           1.1          0.1      Iris-setosa\n4   30           4.7          3.2           1.6          0.2      Iris-setosa\n5   24           5.1          3.3           1.7          0.5      Iris-setosa\n6  119           7.7          2.6           6.9          2.3   Iris-virginica\n7  141           6.7          3.1           5.6          2.4   Iris-virginica\n8  130           7.2          3.0           5.8          1.6   Iris-virginica\n9   78           6.7          3.0           5.0          1.7  Iris-versicolor\n\n      price\n0  2.377915\n1  2.377915\n2  2.377915\n3  2.377915\n4  2.377915\n5  2.377915\n6  3.006378\n7  3.006378\n8  3.006378\n9  6.300895"
          }, 
          "execution_count": 11, 
          "metadata": {}, 
          "output_type": "execute_result"
        }
      ], 
      "source": "pd.merge(random_df, price_df, how='inner', on='Class').head(10)"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "### Concatenating Additional Samples"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "Another very common way of combining datasets comes up when we obtain additional observations, or rows, which we want to append onto our existing dataset. To start, let's create a random set of observations."
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "As we do this, notice that although we have most of the same variables in our new data set, they're not exactly the same as the variables in our original dataset. For instance, our new data includes a new variable called *Petal_Color* but does not include *Sepal_Length*"
    }, 
    {
      "cell_type": "code", 
      "execution_count": 12, 
      "metadata": {}, 
      "outputs": [
        {
          "data": {
            "text/plain": "         Class   ID  Sepal_Width  Petal_Length  Petal_Width Petal_Color\n0  Iris-fakosa  200     9.294842      6.766162     3.376811      purple\n1  Iris-fakosa  201     1.736263      9.140519     4.137983       green\n2  Iris-fakosa  202     7.352583      4.589010     9.238607         red\n3  Iris-fakosa  203     9.590828      1.936722     2.998982      yellow\n4  Iris-fakosa  204     6.466286      8.194248     0.071428      yellow"
          }, 
          "execution_count": 12, 
          "metadata": {}, 
          "output_type": "execute_result"
        }
      ], 
      "source": "# sample randomly generated samples of our new class of iris\ndata = {'Class' : ['Iris-fakosa'] * 5,\n        'ID': range(200,205),\n        'Sepal_Length' : np.random.uniform(0,10,5),\n        'Sepal_Width' : np.random.uniform(0,10,5),\n        'Petal_Length' : np.random.uniform(0,10,5),\n        'Petal_Width' : np.random.uniform(0,10,5),\n        'Petal_Color' : ['purple', 'green', 'red', 'yellow', 'yellow']}\n\nmore_samples_df = pd.DataFrame(data,columns=['Class',\n                                             'ID',\n                                            'Sepal_Width',\n                                            'Petal_Length',\n                                            'Petal_Width',\n                                            'Petal_Color'])\n\nmore_samples_df"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "Now, let's actually append the new data to the bottom of the original data."
    }, 
    {
      "cell_type": "code", 
      "execution_count": 13, 
      "metadata": {}, 
      "outputs": [
        {
          "data": {
            "text/plain": "               Class   ID Petal_Color  Petal_Length  Petal_Width  \\\n36       Iris-setosa   37         NaN      1.300000     0.200000\n118   Iris-virginica  119         NaN      6.900000     2.300000\n140   Iris-virginica  141         NaN      5.600000     2.400000\n42       Iris-setosa   43         NaN      1.300000     0.200000\n25       Iris-setosa   26         NaN      1.600000     0.200000\n77   Iris-versicolor   78         NaN      5.000000     1.700000\n13       Iris-setosa   14         NaN      1.100000     0.100000\n29       Iris-setosa   30         NaN      1.600000     0.200000\n23       Iris-setosa   24         NaN      1.700000     0.500000\n129   Iris-virginica  130         NaN      5.800000     1.600000\n0        Iris-fakosa  200      purple      6.766162     3.376811\n1        Iris-fakosa  201       green      9.140519     4.137983\n2        Iris-fakosa  202         red      4.589010     9.238607\n3        Iris-fakosa  203      yellow      1.936722     2.998982\n4        Iris-fakosa  204      yellow      8.194248     0.071428\n\n     Sepal_Length  Sepal_Width\n36            5.5     3.500000\n118           7.7     2.600000\n140           6.7     3.100000\n42            4.4     3.200000\n25            5.0     3.000000\n77            6.7     3.000000\n13            4.3     3.000000\n29            4.7     3.200000\n23            5.1     3.300000\n129           7.2     3.000000\n0             NaN     9.294842\n1             NaN     1.736263\n2             NaN     7.352583\n3             NaN     9.590828\n4             NaN     6.466286"
          }, 
          "execution_count": 13, 
          "metadata": {}, 
          "output_type": "execute_result"
        }
      ], 
      "source": "random_df.append(more_samples_df).tail(20)"
    }, 
    {
      "cell_type": "markdown", 
      "metadata": {}, 
      "source": "As you can see, the *append()* was smart! It recognized the observations did not all include the same variables and left room appropriately in the table to represent that there was missing data. Furthermore, it used the NaN to represent the missing data so that any subsequent functions would recognize that the data was missing."
    }
  ], 
  "metadata": {}, 
  "nbformat": 4, 
  "nbformat_minor": 0
}