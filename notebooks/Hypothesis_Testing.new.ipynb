{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A Recipe Book for Hypothesis Testing\n",
    "### The Steps\n",
    "If youve followed along this far, then the process of performing a hypothesis test is pretty mechanical. Well assume that we have a sample set of data which has been drawn so that it is a reasonable representation of the larger population. If were planning to make a decision based upon the testing, we should also determine the probability threshold for the decision, $\\alpha$ as well. From here, we can lay out the steps that well follow in each of our recipes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) **Create the null and alternative hypothesis**: Start with the null hypothesis H~0~, which is essentially a claim that there is no difference. The opposing hypothesis, or alternative hypothesis, H~1~ is a claim that there is a difference.\n",
    "b) **Construct a test statistic from the data**: There are multiple types of test statistics that can be plausibly used, depending on the information thats available to you. For the most part, well assume that we have at least 30 samples so that we can assume that the central limit theorem will hold. In cases where we know the population standard deviation, well use z-statistics. In cases where we dont know the population standard deviation, and need to estimate it from the data, well use t-statistics.\n",
    "c) **Convert the test statistic into a p-value**: Once we have our test statistic, we use an appropriate table to convert it into something called a P-value, which tells us the probability of observing data that is at least as extreme as the current sample set.\n",
    "d) **Draw your conclusion**: Compare the P-value to $\\alpha$. If $P \\le \\alpha$ then we can reject the null hypothesis, otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Sample Z-Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Usage:** compares a sample mean to an expected value, typically used to represent the norm. \n",
    "- **Specific requirements**: Depends on knowing the population standard deviation, $\\sigma$ \n",
    "- **Some Notation**: \n",
    "\tLet \n",
    "\t- $\\mu_0$ = the expected value youre testing the sample against, typically the population mean\n",
    "\t- $N$ = the number of samples\n",
    "\t- $\\sigma$ = the population standard deviation under the null hypothesis\n",
    "Assume that both of these quantities are known\n",
    "- **Performing a One Sided Test**: \n",
    "\t1. Formulate the null hypothesis, which in this case is that the sample mean is the same as the assumed mean. \n",
    "\t2. Formulate the alternate hypothesis, specifically that the population mean is *higher* from the assumed mean. Well come back to other alternative hypotheses in a moment\n",
    "\t3. Compute the sample mean $\\bar{x}$\n",
    "\t4. Compute the standard error, $$SE = \\frac{\\sigma}{\\sqrt{N}}$$\n",
    "\t5. Compute the test statistic: $$z_{stat} = \\frac{\\bar{x} - \\mu_0}{SE}$$\n",
    "\t6. Convert the statistic to a P-value by finding the area under the curve beyond the $z_{stat}$ on a Standard Normal distribution[^norms]. \n",
    "\t\n",
    "- **Performing a Two Sided Test**\n",
    "Now, let's consider the other formulation of the alternate hypothesis, i.e. that the means are different, not necessarily higher:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\t1. Formulate the null hypothesis, which in this case is that the sample mean is the same as the expected value. \n",
    "\t2. Formulate the alternate hypothesis, specifically that the population mean is *not equal* from the assumed mean.\n",
    "\t3. Compute the sample mean $\\bar{x}$\n",
    "\t4. Compute the standard error, $$SE = \\frac{\\sigma}{\\sqrt{N}}$$\n",
    "\t5. Compute the test statistic: $$z_{stat} = \\frac{\\bar{x} - \\mu_0}{SE}$$\n",
    "\t6. Convert the statistic to a P-value. In this case, well reject the null if the mean is either significantly greater *or* significantly less than $\\mu_0$, so our P-value must include the probabilities from both of the tails on the Normal distribution. Again, we can find these areas using a Standard Normal Distribution. Mechanically, the easiest way to do so is to take advantage of the symmetry of the Normal distribution by computing the area under the curve to the right of the $z_{stat}$, and then just doubling it to obtain the two-sided P-value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Sample T-Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prior examples focused on using the statistic to test a sample mean against an expected value. Constructing the $z_{stat}$ required us to have the population standard deviation $\\sigma$ to determine the standard error. Unfortunately, if we dont have $\\sigma$ and are forced to estimate it from the data, then we cant use the Z-Tests. Instead we use a variation called a T-Test which uses the sample standard deviation $s$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Usage:** compares a sample mean to an expected value, typically used to represent the norm. Used when the population standard deviation is not known\n",
    "- **Some Notation**: \n",
    "Let \n",
    "\t- $\\mu_0$ = the population mean under the null hypothesis\n",
    "\t- $N$ = the number of samples\n",
    "\t- $s$ = the sample standard deviation\n",
    "- **Performing a Two Sided Test**: \n",
    "\t1. Formulate the null hypothesis, which in this case is that the sample mean is the same as the assumed mean. \n",
    "\t2. Formulate the alternate hypothesis, specifically that the population mean is *higher* from the assumed mean. Well come back to other alternative hypotheses in a moment\n",
    "\t3. Compute the sample mean $\\bar{x}$\n",
    "\t4. Compute the standard error, $$SE = \\frac{s}{\\sqrt{N}}$$\n",
    "\t5. Compute the test statistic: $$t_{stat} = \\frac{\\bar{x} - \\mu_0}{SE}$$\n",
    "\t6. We say that this statistic has $N-1$ degrees of freedom\n",
    "\t6. Convert the statistic to a P-value by using the $t_{stat}$ on a Students T distribution with $N-1$ degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Two Sample T-Tests Assuming Equal Population Variances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A Two Sample Test is pretty much what it sounds like: a hypothesis test involving two independent samples. Constructing these will generally take on the form of the recipes  just presented, however we need to take care to account for both samples having a dispersion. Since well be using a T-Test again, well also need to address the computation of the degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before presenting the recipe, remember that in the One Sample T-Test we used the sample standard deviation as the basis for computing the standard error. Well do the same thing here, but now we have two sets of data and, by extension, two sample standard deviations which well need to combine somehow in order to construct the standard error and, eventually the T-statistic. The way that well perform this aggregation is to construct what is called a *pooled standard deviation*, which is essentially a weighted average of the standard deviations of each of the independent groups. Without going into details, the pooled standard deviation is given by"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$S_p = \\sqrt{\\frac{(N_1 - 1) S_1^2 + (N_2 - 1) S_2^2}{(N_1 - 1) + (N_2 - 1)}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Usage:** compares two independent samples when the population standard deviation is not known\n",
    "- **Some Notation**: \n",
    "Let \n",
    "\t- $N_1$ = the number of samples in Sample 1\n",
    "\t- $N_2$ = the number of samples in Sample 2\n",
    "- **Performing a Two Sided Test**: \n",
    "\t1. Formulate the null hypothesis, which in this case is that the sample mean is the same as the assumed mean. \n",
    "\t2. Formulate the alternate hypothesis, specifically that the population mean is *higher* from the assumed mean. Well come back to other alternative hypotheses in a moment\n",
    "\t3. Compute the sample means of each group $\\bar{X}$ and $\\bar{Y}$\n",
    "\t4. Compute the pooled standard deviation, \n",
    "\t$$S_p = \\sqrt{\\frac{(N_1 - 1) S_1^2 + (N_2 - 1) S_2^2}{(N_1 - 1) + (N_2 - 1)}}$$\n",
    "\t5. Compute the test statistic: \n",
    "\t$$t_{stat} = \\frac{\\bar{X} - \\bar{Y}}{S_p\\sqrt{\\frac{1}{N_1} + \\frac{1}{N_2}}}$$\n",
    "\t6. We say that this statistic has $dof = N_1 + N_2 - 2$ degrees of freedom\n",
    "\t6. Convert the statistic to a P-value by using the $t_{stat}$ on a Students T distribution with $dof$ degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note:* There is another test, which we wont cover here, which handles the case when we assume that we have two unequal population variances. This test, called Welchs T-Test, can generally be applied to the equal variance case. The recipe for Welchs T-Test is essentially the similar in spirit to the one presented here, but it differs significantly in the computation of the number of degrees of freedom."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paired T-Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What happens if we want to compare two population means where you have two samples in which observations in one sample can be paired with observations in the other sample. Examples of where this might occur are:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Before-and-after observations on the same subjects (e.g. students test results before and after a particular module or course).\n",
    "- A comparison of two different methods of measurement or two different treatments where the measurements/treatments are applied to the same subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, it feels like we should apply a Two Sample Test. However, the ability to pair the data allows us to recast the problem as a One Sample Test, which in this case will have considerably more power."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECIPE**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Usage:** compares two samples where the samples can be paired. \n",
    "- **Some Notation**: Let\n",
    "\t- $\\mu_0$ = the population mean under the null hypothesis\n",
    "\t- $N$ = the number of samples, which is assumed to be the same in both sets\n",
    "\t- $X = \\{ x_1, x_2, \\dots, x_N \\}$ be the first sample\n",
    "\t- $Y = \\{ y_1, y_2, \\dots, y_N \\}$ be the second sample \n",
    "- **Performing a Two Sided Test**: \n",
    "\t1. Formulate the null hypothesis, which in this case is that the true mean difference is zero. \n",
    "\t3. Calculate the differences between each pair of samples $d_i = y_i - x_i$,\n",
    "\t4. Compute the mean difference $\\bar{d}$\n",
    "\t4. Compute the standard deviation of the differences, $s_d$ \n",
    "\t5. Compute the standard error of the mean difference $$SE(\\bar{d}) = \\frac{s_d}{\\sqrt{N}}$$\n",
    "\t5. Compute the test statistic: $$t_{stat} = \\frac{\\bar{d}}{SE(\\bar{d})}$$\n",
    "\t6. We say that this statistic has $N-1$ degrees of freedom\n",
    "\t6. Convert the statistic to a P-value by using the $t_{stat}$ on a Students T distribution with $N-1$ degrees of freedom. \n",
    "\t\n",
    "## Some Things To Keep an Eye Out For in Hypothesis Testing\n",
    "The results of statistical tests can be confusing to interpret so you might find it useful to keep these items in mind, since they come up quite often as mistakes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Failure to reject the null hypothesis leads to its acceptance**.  Nope. The failure to reject the null hypothesis only means that you have insufficient evidence for its rejection. \n",
    "2. **The p value is the probability that the null hypothesis is incorrect.** Nope. The p value is the probability of data that is at least as extreme as the sample data, assuming H~0~ is true.\n",
    "3. **$\\alpha = .05$ is a standard with an objective basis.** Nope.  $\\alpha$ = .05 is just a convention. There is no sharp distinction between significant and insignificant results, only increasingly strong evidence as the p value gets smaller. \n",
    "4. **Small p values indicate large effects**. Nope. p values tell you next to nothing about the size of an effect.\n",
    "5. **Statistical significance implies importance.** Nope. Statistical significance says very little about the importance of a relation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Some Definitions\n",
    "* **Null Hypothesis** ($H_0$): More formally, the statement that the observed differences in the data were due to chance.\n",
    "* **Alternative Hypothesis** ($H_1$): The opposite of the null hypothesis. \n",
    "* **Alpha** ($\\alpha$) - The probability the researcher is willing to take in falsely rejecting a true null hypothesis. Typical values might be $\\alpha = 0.90$ or $\\alpha = 0.95$\n",
    "* **Test statistic** - A statistic used to test the null hypothesis. The formulation of this statistic will vary based upon the assumed distribution (e.g. the Students T Distribution, the Normal, etc.).\n",
    "* **P-value** - A probability statement that answers the question If the null hypothesis were true, what is the probability of observing the current data or data that is more extreme than the current data?. It is NOT the probability that the null hypothesis is true.\n",
    "* **Type I error** - a rejection of a true null hypothesis; a false alarm.\n",
    "* **Type II error** - a retention of an incorrect null hypothesis, or a missed detection\n",
    "* **Confidence** (1 - $\\alpha$) - the complement of alpha."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    ">>> # We're going to plot all of the figures within the notebook, so let's set up that option\n",
    "... # Our standard set of imports for pandas, numpy and matplotlib\n",
    "... import pandas as pd\n",
    ">>> import numpy as np\n",
    ">>> import matplotlib as mpl\n",
    ">>> import matplotlib.pyplot as plt\n",
    ">>> from ipywidgets import interact\n",
    "...\n",
    ">>> # in addition, it will be useful in general if we keep our plots \"inline\" within the notebook\n",
    "... %matplotlib inline\n",
    "...\n",
    ">>> mpl.style.use('ggplot')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm sure that this is entirely review for everyone, but let's take a moment to think about probability distributions. For most people, the distribution that may come to mind first is the Gaussian, or Normal, probability distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gaussian Distributions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import math\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "# set up the pdf for the standard distribution\n",
    "mean = 0\n",
    "variance = 1\n",
    "sigma = math.sqrt(variance)\n",
    "x = np.linspace(-4,4,100);\n",
    "\n",
    "# compute the CDF\n",
    "y = mlab.normpdf(x,mean,sigma);\n",
    "yCum = y.cumsum();\n",
    "yCum /= yCum[-1];\n",
    "\n",
    "def fillGaussian(t):\n",
    "    section = np.linspace(-4, t, 40)\n",
    "    yFill = mlab.normpdf(section,mean,sigma)\n",
    "\n",
    "    # determine the area that will be filled\n",
    "    # and now draw everything\n",
    "    fig, ax1 = plt.subplots(1, 1, sharex=True)\n",
    "    fig.set_size_inches(15,10)\n",
    "    ax1.plot(x, y, 'b', linewidth=1.5)\n",
    "    ax1.plot(x, yCum, 'r--', linewidth=1.5)\n",
    "    ax1.fill_between(section,0.0, yFill, color='Green', alpha=0.5)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "interact(fillGaussian, t=(-4.0,4.0));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we talk about anything else, let's stop for a moment and consider probability distributions. More specifically, let's think about our ability to estimate a probability distribution given a sample of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from   matplotlib import mlab\n",
    "\n",
    "mean = 200\n",
    "variance = 25\n",
    "n_bins = 50\n",
    "\n",
    "sigma = math.sqrt(variance)\n",
    "\n",
    "x = mean + sigma*np.random.randn(25)\n",
    "\n",
    "n, bins, patches = plt.hist(x, n_bins, normed=1, histtype='step', cumulative=True)\n",
    "\n",
    "# Add a line showing the expected distribution.\n",
    "y = mlab.normpdf(bins, mean, sigma).cumsum()\n",
    "y /= y[-1]\n",
    "\n",
    "# Now plot out both the expected CDF and the actual CDF\n",
    "plt.plot(bins, y, 'k--', linewidth=1.5)\n",
    "plt.grid(True)\n",
    "plt.ylim(0, 1.05)\n",
    "plt.title('Cumulative Distribution')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical Distributions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Normal Approximation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing this process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "import math\n",
    "\n",
    "from ipywidgets import interact\n",
    "\n",
    "# set up the pdf for the standard distribution\n",
    "mean = 0\n",
    "variance = 1\n",
    "sigma = math.sqrt(variance)\n",
    "x = np.linspace(-4,4,100);\n",
    "\n",
    "# compute the CDF\n",
    "y = mlab.normpdf(x,mean,sigma);\n",
    "yCum = y.cumsum();\n",
    "yCum /= yCum[-1];\n",
    "\n",
    "def fillGaussian(t):\n",
    "    section = np.linspace(t, 4, 20)\n",
    "    yFill = mlab.normpdf(section,mean,sigma)\n",
    "\n",
    "    # determine the area that will be filled\n",
    "    # and now draw everything\n",
    "    fig, ax1 = plt.subplots(1, 1, sharex=True)\n",
    "    fig.set_size_inches(15,10)\n",
    "    ax1.plot(x, y, 'b', linewidth=1.5)\n",
    "    ax1.plot(x, yCum, 'r--', linewidth=1.5)\n",
    "    ax1.fill_between(section,0.0, yFill, color='Green', alpha=0.5)\n",
    "    plt.ylim(0, 1.05)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    return\n",
    "\n",
    "interact(fillGaussian, t=(0.0,4.0));"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 0
}